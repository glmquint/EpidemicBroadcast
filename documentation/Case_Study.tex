\section{Case Study: 200 Nodes}
\subsection{Introduction}
In this chapter we analyze the case at 200 nodes, as it is the quantity that is halfway between our configurations. At the end of the simulations we decide to calculate the average coverage percentage, summarized in this table.

\begin{table}[h!]
\centering
\begin{tabular}{|c|c|c|c|c|c|}
\hline
       & r=10    & r=30    & r=50    & r=75    & r=100   \\ \hline
p=0,15 & 0,90727 & 1       & 1       & 1       & 1       \\ \hline
p=0,3  & 0,89379 & 0,99924 & 0,99561 & 1       & 0,99924 \\ \hline
p=0,5  & 0,79909 & 0,99424 & 0,98803 & 0,98894 & 0,99591 \\ \hline
p=0,7  & 0,71045 & 0,97985 & 0,96455 & 0,93727 & 0,9903  \\ \hline
p=0,85 & 0,57303 & 0,94212 & 0,90212 & 0,91833 & 0,9797  \\ \hline
p=1    & 0,47545 & 0,81909 & 0,67121 & 0,76303 & 0,96727 \\ \hline
\end{tabular}
\caption{Mean coverage percentage}
\label{tab:mean-coverage-percentage}
\end{table}

Since the mean does not give enough information about the index variation, we decide to calculate the standard deviation as well.
\begin{table}[h!]
\centering
\begin{tabular}{|l|l|l|l|l|l|}
\hline
       & r=10    & r=30    & r=50    & r=75    & r=100   \\ \hline
p=0,15 & 0,16006 & 0       & 0       & 0       & 0       \\ \hline
p=0,3  & 0,12149 & 0,00283 & 0,01886 & 0       & 0,00435 \\ \hline
p=0,5  & 0,21101 & 0,00686 & 0,0454  & 0,02858 & 0,01618 \\ \hline
p=0,7  & 0,24243 & 0,02438 & 0,06648 & 0,09235 & 0,02274 \\ \hline
p=0,85 & 0,26813 & 0,06087 & 0,11409 & 0,11198 & 0,03477 \\ \hline
p=1    & 0,27804 & 0,14129 & 0,17092 & 0,12449 & 0,03833 \\ \hline
\end{tabular}
\caption{Standard deviation of the coverage percentage}
\label{tab:std-coverage-percentage}
\end{table}

In this way we exclude the configurations whose difference between mean and standard deviation is less than 90\%. We are interested in configurations that have a satisfactory coverage percentage, as these configurations model a reliable system.
\begin{table}[h!]
\centering
\begin{tabular}{|l|l|l|l|l|l|}
\hline
       & r=10    & r=30                            & r=50                            & r=75                            & r=100                           \\ \hline
p=0,15 & 0,74721 & \cellcolor[HTML]{92D050}1       & \cellcolor[HTML]{92D050}1       & \cellcolor[HTML]{92D050}1       & \cellcolor[HTML]{92D050}1       \\ \hline
p=0,3  & 0,7723  & \cellcolor[HTML]{92D050}0,99641 & \cellcolor[HTML]{92D050}0,97674 & \cellcolor[HTML]{92D050}1       & \cellcolor[HTML]{92D050}0,99489 \\ \hline
p=0,5  & 0,58808 & \cellcolor[HTML]{92D050}0,98738 & \cellcolor[HTML]{92D050}0,94263 & \cellcolor[HTML]{92D050}0,96036 & \cellcolor[HTML]{92D050}0,97973 \\ \hline
p=0,7  & 0,46802 & \cellcolor[HTML]{92D050}0,95547 & 0,89807                         & 0,84492                         & \cellcolor[HTML]{92D050}0,96756 \\ \hline
p=0,85 & 0,3049  & 0,88125                         & 0,78803                         & 0,80636                         & \cellcolor[HTML]{92D050}0,94492 \\ \hline
p=1    & 0,19741 & 0,67781                         & 0,5003                          & 0,63854                         & \cellcolor[HTML]{92D050}0,92895 \\ \hline
\end{tabular}
\caption{Runs that we decide to analyze}
\label{tab:run-to-analyze}
\end{table}

\subsection{Performance indexes} \label{200Index}
After selecting the runs to be analysed, we choose to plot the most interesting performance indicators such as: the coverage percentage (Figure \ref{fig:coverage-percentage}), the completion time (Figure \ref{fig:coverage-time200}) and the mean percentage of collisions for each time-slot (Figure \ref{fig:mean-collision-rate200}). For symmetry, the graphs also show configurations, such as the one with probability 0.7 and radius 75, even if they  should not be considered as shown in Table \ref{tab:run-to-analyze}.

\begin{figure}[h!]
\centering
    \includegraphics[width= 1\textwidth]{./images/Rate200Boxplot.png}
    \caption{Coverage percentage}
    \label{fig:coverage-percentage}
\end{figure}


\begin{figure}[h!]
\centering
    \includegraphics[width= 1\textwidth]{./images/Time200Boxplot.png}
    \caption{Coverage time}
    \label{fig:coverage-time200}
\end{figure}

\clearpage 

\begin{figure}[h!]
\centering
    \includegraphics[width= 1\textwidth]{./images/Collision200Boxplot.png}
    \caption{Mean collision rate}
    \label{fig:mean-collision-rate200}
\end{figure}

\noindent Looking at coverage percentage graph (Fig. \ref{fig:coverage-percentage}), it can be seen that increasing the probability does not give better coverage in most cases, as one would expect. In fact, it should be emphasized that as the probability increases, collisions also tend to increase accordingly. As imagined, the coverage time (Fig. \ref{fig:coverage-time200}) decreases as the probability increases, as a higher probability translates into more nodes that can send the infection message. Regarding the collision index (Fig \ref{fig:mean-collision-rate200}), the average values were obtained for each repetition. For this index, as expected, there is an increasing trend with the growth of probability which implies that more nodes can transmit the message in the same time-slot. It also should be noted that the cases with 75 and 100 radii do not follow the highlighted patters: the reason why is because, as the radius and the probability increase, the possibility of having many nodes reached by the infection message in the first instant is high.
\clearpage 

\subsection{Hierarchy of priorities}
Thinking of a real system we have elaborated a hierarchy of priorities to try to understand which system was the most adherent to these characteristics:

\begin{enumerate}
\item High coverage percentage
\item Minimum coverage time
\item Minimum collision percentage
\end{enumerate}

Considering runs of interest, as highlighted in Table \ref{tab:run-to-analyze}, we filter only those with $(p=0.15)$ and with $(p=0.3;r=75)$, as they are the only configurations always covering all nodes.
We can rank them based on the coverage time, using Figure \ref{fig:coverage-time200} and we see that an increase in probability is clearly beneficial for a system speed-up although with a diminishing return. We can observe that the third quartile for $p=0.3$, $r=75$ is strictly below the first quartile for every configuration with $p=0.15$ and thus we can assert with a confidence level of at least 75\% that this configuration is faster. Therefore we choose it as the best trade-off to analyze.

\subsection{Time evolution}
Thanks to the data collected, we have the state of the system for each instant of time, and we are able to analyze the temporal evolution of the system. Considering the case with 200 nodes, we examine all four combinations of radius $(10-75)$ and probability $(0.15-0.85)$, plus the special configuration $p=0.30$ and $r=75$. 
Figure \ref{fig:done-status} is plotted on a linear time scale and shows the relative speed of completion for the different configuration. In particular, it is evident the negative impact given by a small probability of transmission, especially if coupled with a small radius. 
Unfortunately, this figure doesn't show confidence intervals, as they would clutter the graph too much, particularly in the most critical initial instants. 
Figure \ref{fig:done-status-log} tries to fix this problem by employing a logarithmic scale on the time axis. This allows us to better define differences between configurations, as the colored areas represent the first and third quartiles. It is clear that the special configuration $p=0.30$ and $r=75$ is the fastest one between those that reach a complete coverage. 
Increasing the probability makes the system faster given that we increase the radius too: this is the difference between the configuration $p=0.85\,r=75$, which is the fastest to reach $85\%$ coverage with a $75\%$ confidence level, and the configuration $p=0.85\,r=10$, which has a higher chance of representing an unconnected graph. 
Finally, if the problem imposes a small radius, it is clear that drastically reducing the probability (configuration $p=0.15\,r=10$) guarantees a coverage of at least $90\%$ with a $75\%$ confidence level, as we get much fewer collisions. Obviously we must accept the fact that this implies a much longer wait before reaching the final state.
%which is the preferred one, considering the priorities previously considered. Indeed, we can 
\begin{figure}[H]
\centering
    \includegraphics[width= 1\textwidth]{./images/temporalDone.png}
    \caption{Mean done status}
    \label{fig:done-status}
\end{figure}
\begin{figure}[H]
\centering
    \includegraphics[width= 1\textwidth]{./images/temporalDoneLog.png}
    \caption{Done status on a logarithmic scale with mean and quartiles}
    \label{fig:done-status-log}
\end{figure}

\subsection{Factorial Analysis of ending time and ending coverage}

We compute a $2^k$ factorial analysis to highlight the influence of radius $r$ and probability $p$ on two of our performance indexes, fitting the output variable to a bi-dimensional nonlinear regression model in the form of 
$$
y = q_0 + q_R \cdot r + q_P \cdot p + q_{RP} \cdot r \cdot p
$$

Starting with the final node coverage, i.e. the fraction of nodes in the Done status at the end of simulation, extreme values are shown in Table \ref{tab:extreme-factors-end-coverage} and the final influence in Table \ref{tab:influence-on-end-coverage}. It is important to notice that the extremes do not include a sending probability of 100\% and radius of 100 because we decide to handle these as particular configurations that serve only to show the limit cases for the system.


\begin{table}[h!]
\centering
\begin{tabular}{|cc|cc|}
\hline
\multicolumn{2}{|c|}{\multirow{2}{*}{\textbf{Asymptote}}} & \multicolumn{2}{c|}{\textbf{Radius}} \\ \cline{3-4} 
\multicolumn{2}{|c|}{} & \multicolumn{1}{c|}{\textbf{10}} & \textbf{75} \\ \hline
\multicolumn{1}{|c|}{\multirow{2}{*}{\textbf{Probability}}} & \textbf{15} & \multicolumn{1}{c|}{0,9073} & 1,0000 \\ \cline{2-4} 
\multicolumn{1}{|c|}{} & \textbf{85} & \multicolumn{1}{c|}{0,5730} & 0,9183 \\ \hline
\end{tabular}
\caption{Extreme factor levels for ending coverage}
\label{tab:extreme-factors-end-coverage}
\end{table}


\begin{table}[H]
\centering
\begin{tabular}{|l|l|l|l|l|l|l|}
\hline
                       & I        & Prob     & Radius   & RP       &          &          \\ \hline
                       & 1        & -1       & -1       & 1        & 0,907273 & 0,003319 \\ \hline
                       & 1        & 1        & -1       & -1       & 0,57303  & 0,076523 \\ \hline
                       & 1        & -1       & 1        & -1       & 1        & 0,022602 \\ \hline
                       & 1        & 1        & 1        & 1        & 0,918333 & 0,004716 \\ \hline
4q                     & 3,398636 & -0,41591 & 0,43803  & 0,252576 &          & 0,107161 \\ \hline
q                      & 0,849659 & -0,10398 & 0,109508 & 0,063144 &          &          \\ \hline
4 q\textasciicircum{}2 &          & 0,043245 & 0,047968 & 0,015949 &          &          \\ \hline
                       &          &          &          &          &          &          \\ \hline
Influenza              &          & 0,403551 & 0,447621 & 0,148828 &          &          \\ \hline

\end{tabular}
\caption{Influence of factors for ending coverage}
\label{tab:influence-on-end-coverage}
\end{table}


We get a pretty balanced influence between radius and probability of about $\sim 42\%$ each, although we must notice that the term $q_P$ is negative $(-0.10)$, which implies a reduction of the final coverage with an increase in probability. Looking at Figure \ref{fig:mean-collision-rate200} we can clearly understand that this is primarily due to an increase in collisions, which naturally reflects the much lower coverage. Finally, we can assess that the interaction of both parameters is relatively small $(14\%)$, and thus we can study the system by just fixing one parameter and varying the other.

Regarding the completion time, the extreme values are shown in Table \ref{tab:extreme-factors-time-coverage} and influences in Table \ref{tab:influence-on-time-coverage}

\begin{table}[h!]
\centering
\begin{tabular}{|cc|cc|}
\hline
\multicolumn{2}{|c|}{\multirow{2}{*}{\textbf{Displacement}}} & \multicolumn{2}{c|}{\textbf{Radius}} \\ \cline{3-4} 
\multicolumn{2}{|c|}{} & \multicolumn{1}{c|}{\textbf{10}} & \textbf{75} \\ \hline
\multicolumn{1}{|c|}{\multirow{2}{*}{\textbf{Probability}}} & \textbf{15} & \multicolumn{1}{c|}{111,0152} & 47,6515 \\ \cline{2-4} 
\multicolumn{1}{|c|}{} & \textbf{85} & \multicolumn{1}{c|}{21,4091} & 7,2576 \\ \hline
\end{tabular}
\caption{Extreme level of factors for time coverage}
\label{tab:extreme-factors-time-coverage}
\end{table}

\begin{table}[h!]
\centering
\begin{tabular}{c|c|c|c|c|cc}
\cline{2-7}
 & \textbf{I} & \textbf{Probability} & \textbf{Radius} & \textbf{Combined} & \multicolumn{1}{c|}{} & \multicolumn{1}{c|}{} \\ \cline{2-7} 
 & 1 & -1 & -1 & 1 & \multicolumn{1}{c|}{111,0152} & \multicolumn{1}{c|}{4119,3058} \\ \cline{2-7} 
 & 1 & 1 & -1 & -1 & \multicolumn{1}{c|}{21,4091} & \multicolumn{1}{c|}{646,3921} \\ \cline{2-7} 
 & 1 & -1 & 1 & -1 & \multicolumn{1}{c|}{47,6515} & \multicolumn{1}{c|}{0,6694} \\ \cline{2-7} 
 & 1 & 1 & 1 & 1 & \multicolumn{1}{c|}{7,2576} & \multicolumn{1}{c|}{1566,2406} \\ \hline
\multicolumn{1}{|c|}{\textbf{4q}} & 187,3333 & -130,0000 & -77,5152 & 49,2121 & \multicolumn{1}{c|}{Total} & \multicolumn{1}{c|}{6332,6079} \\ \hline
\multicolumn{1}{|c|}{\textbf{q}} & 46,8333 & -32,5000 & -19,3788 & 12,3030 &  &  \\ \cline{1-5}
\multicolumn{1}{|c|}{\textbf{4 q\textasciicircum{}2}} &  & 4225,0000 & 1502,1497 & 605,4582 &  &  \\ \cline{1-5}
\multicolumn{1}{|c|}{\textbf{Influence}} &  & 0,6672 & 0,2372 & 0,0956 &  &  \\ \cline{1-5}
\end{tabular}
\caption{Influence of factors for time coverage}
\label{tab:influence-on-time-coverage}
\end{table}

It is clear that having both negative coefficients ($q_P = -32.50$ and $q_R = -19.38$) is beneficial for a faster system termination (lower is better). The probability is also $\sim\times 3$ more effective at reducing the completion time, which is also stated by Figure \ref{fig:coverage-time200} and is in line with what is expected: even if it means having more collisions, having a higher probability reduces the time a node waits in the Ready status. Again, the interaction of both parameters is negligible and allows us to study the effect of each parameter separately.
